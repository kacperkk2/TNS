{
 "cells": [
  {
   "source": [
    "## Extract sentences from a book"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "SHERLOCK = 'sher'\n",
    "METAMORPHOSIS = 'meta'\n",
    "PRIDE = 'prid'\n",
    "chosen_book = PRIDE\n",
    "book_files = {\n",
    "    SHERLOCK: 'words_data/sherlock/the_adventures_of_sherlock_holmes-arthur_conan_doyle.txt',\n",
    "    PRIDE: 'words_data/pride_and_prejudice/pride_and_prejudice-jane_austen.txt'\n",
    "}\n",
    "sentences = []\n",
    "sentence_regex = re.compile(r'([A-Z][^\\.!?]*[\\.!?])', re.M)\n",
    "with open(book_files[chosen_book], 'r') as bookfile:\n",
    "    whole_book = bookfile.read()\n",
    "    sentences = re.findall(sentence_regex, whole_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7019"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Chapter 1\\n\\n      It is a truth universally acknowledged, that a single man in\\n      possession of a good fortune, must be in want of a wife.',\n",
       " 'However little known the feelings or views of such a man may be\\n      on his first entering a neighbourhood, this truth is so well\\n      fixed in the minds of the surrounding families, that he is\\n      considered the rightful property of some one or other of their\\n      daughters.',\n",
       " 'My dear Mr.',\n",
       " 'Bennet,” said his lady to him one day, “have you\\n      heard that Netherfield Park is let at last?',\n",
       " 'Mr.',\n",
       " 'Bennet replied that he had not.',\n",
       " 'But it is,” returned she; “for Mrs.',\n",
       " 'Long has just been here, and\\n      she told me all about it.',\n",
       " 'Mr.',\n",
       " 'Bennet made no answer.']"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Chapter 1\\n\\n      It is a truth universally acknowledged, that a single man in\\n      possession of a good fortune, must be in want of a wife.',\n",
       " 'However little known the feelings or views of such a man may be\\n      on his first entering a neighbourhood, this truth is so well\\n      fixed in the minds of the surrounding families, that he is\\n      considered the rightful property of some one or other of their\\n      daughters.',\n",
       " 'My dear Mr.',\n",
       " 'Bennet,” said his lady to him one day, “have you\\n      heard that Netherfield Park is let at last?',\n",
       " 'Bennet replied that he had not.',\n",
       " 'But it is,” returned she; “for Mrs.',\n",
       " 'Long has just been here, and\\n      she told me all about it.',\n",
       " 'Bennet made no answer.',\n",
       " 'Do you not want to know who has taken it?',\n",
       " 'You_ want to tell me, and I have no objection to hearing it.']"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "starting_sentence = {\n",
    "    SHERLOCK: 0,\n",
    "    METAMORPHOSIS: 8,\n",
    "    PRIDE: 0\n",
    "}\n",
    "messages = []\n",
    "for sentence in sentences[starting_sentence[chosen_book]:]:\n",
    "    if len(sentence.split(' ')) >= 2:\n",
    "        messages.append(sentence)\n",
    "messages[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6543"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitize messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/piotrm/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Chapter',\n",
       "  '1',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'truth',\n",
       "  'universally',\n",
       "  'acknowledged',\n",
       "  ',',\n",
       "  'that',\n",
       "  'a',\n",
       "  'single',\n",
       "  'man',\n",
       "  'in',\n",
       "  'possession',\n",
       "  'of',\n",
       "  'a',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  ',',\n",
       "  'must',\n",
       "  'be',\n",
       "  'in',\n",
       "  'want',\n",
       "  'of',\n",
       "  'a',\n",
       "  'wife',\n",
       "  '.'],\n",
       " ['However',\n",
       "  'little',\n",
       "  'known',\n",
       "  'the',\n",
       "  'feelings',\n",
       "  'or',\n",
       "  'views',\n",
       "  'of',\n",
       "  'such',\n",
       "  'a',\n",
       "  'man',\n",
       "  'may',\n",
       "  'be',\n",
       "  'on',\n",
       "  'his',\n",
       "  'first',\n",
       "  'entering',\n",
       "  'a',\n",
       "  'neighbourhood',\n",
       "  ',',\n",
       "  'this',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'so',\n",
       "  'well',\n",
       "  'fixed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'minds',\n",
       "  'of',\n",
       "  'the',\n",
       "  'surrounding',\n",
       "  'families',\n",
       "  ',',\n",
       "  'that',\n",
       "  'he',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'the',\n",
       "  'rightful',\n",
       "  'property',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'or',\n",
       "  'other',\n",
       "  'of',\n",
       "  'their',\n",
       "  'daughters',\n",
       "  '.']]"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "# Split into tokens (words+punctuation)\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = [word_tokenize(row) for row in messages]\n",
    "tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Chapter',\n",
       "  '1',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'truth',\n",
       "  'universally',\n",
       "  'acknowledged',\n",
       "  '',\n",
       "  'that',\n",
       "  'a',\n",
       "  'single',\n",
       "  'man',\n",
       "  'in',\n",
       "  'possession',\n",
       "  'of',\n",
       "  'a',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  '',\n",
       "  'must',\n",
       "  'be',\n",
       "  'in',\n",
       "  'want',\n",
       "  'of',\n",
       "  'a',\n",
       "  'wife',\n",
       "  ''],\n",
       " ['However',\n",
       "  'little',\n",
       "  'known',\n",
       "  'the',\n",
       "  'feelings',\n",
       "  'or',\n",
       "  'views',\n",
       "  'of',\n",
       "  'such',\n",
       "  'a',\n",
       "  'man',\n",
       "  'may',\n",
       "  'be',\n",
       "  'on',\n",
       "  'his',\n",
       "  'first',\n",
       "  'entering',\n",
       "  'a',\n",
       "  'neighbourhood',\n",
       "  '',\n",
       "  'this',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'so',\n",
       "  'well',\n",
       "  'fixed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'minds',\n",
       "  'of',\n",
       "  'the',\n",
       "  'surrounding',\n",
       "  'families',\n",
       "  '',\n",
       "  'that',\n",
       "  'he',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'the',\n",
       "  'rightful',\n",
       "  'property',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'or',\n",
       "  'other',\n",
       "  'of',\n",
       "  'their',\n",
       "  'daughters',\n",
       "  '']]"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# Replace puntuation with empty string\n",
    "import string\n",
    "table = str.maketrans('','',string.punctuation)\n",
    "words = [[word.translate(table) for word in line] for line in tokens]\n",
    "words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Chapter',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'truth',\n",
       "  'universally',\n",
       "  'acknowledged',\n",
       "  '',\n",
       "  'that',\n",
       "  'a',\n",
       "  'single',\n",
       "  'man',\n",
       "  'in',\n",
       "  'possession',\n",
       "  'of',\n",
       "  'a',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  '',\n",
       "  'must',\n",
       "  'be',\n",
       "  'in',\n",
       "  'want',\n",
       "  'of',\n",
       "  'a',\n",
       "  'wife',\n",
       "  ''],\n",
       " ['However',\n",
       "  'little',\n",
       "  'known',\n",
       "  'the',\n",
       "  'feelings',\n",
       "  'or',\n",
       "  'views',\n",
       "  'of',\n",
       "  'such',\n",
       "  'a',\n",
       "  'man',\n",
       "  'may',\n",
       "  'be',\n",
       "  'on',\n",
       "  'his',\n",
       "  'first',\n",
       "  'entering',\n",
       "  'a',\n",
       "  'neighbourhood',\n",
       "  '',\n",
       "  'this',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'so',\n",
       "  'well',\n",
       "  'fixed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'minds',\n",
       "  'of',\n",
       "  'the',\n",
       "  'surrounding',\n",
       "  'families',\n",
       "  '',\n",
       "  'that',\n",
       "  'he',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'the',\n",
       "  'rightful',\n",
       "  'property',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'or',\n",
       "  'other',\n",
       "  'of',\n",
       "  'their',\n",
       "  'daughters',\n",
       "  '']]"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "# Remove digits\n",
    "words = [[word for word in line if not word.isdigit()] for line in words]\n",
    "words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['chapter',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'truth',\n",
       "  'universally',\n",
       "  'acknowledged',\n",
       "  'that',\n",
       "  'a',\n",
       "  'single',\n",
       "  'man',\n",
       "  'in',\n",
       "  'possession',\n",
       "  'of',\n",
       "  'a',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'must',\n",
       "  'be',\n",
       "  'in',\n",
       "  'want',\n",
       "  'of',\n",
       "  'a',\n",
       "  'wife'],\n",
       " ['however',\n",
       "  'little',\n",
       "  'known',\n",
       "  'the',\n",
       "  'feelings',\n",
       "  'or',\n",
       "  'views',\n",
       "  'of',\n",
       "  'such',\n",
       "  'a',\n",
       "  'man',\n",
       "  'may',\n",
       "  'be',\n",
       "  'on',\n",
       "  'his',\n",
       "  'first',\n",
       "  'entering',\n",
       "  'a',\n",
       "  'neighbourhood',\n",
       "  'this',\n",
       "  'truth',\n",
       "  'is',\n",
       "  'so',\n",
       "  'well',\n",
       "  'fixed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'minds',\n",
       "  'of',\n",
       "  'the',\n",
       "  'surrounding',\n",
       "  'families',\n",
       "  'that',\n",
       "  'he',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'the',\n",
       "  'rightful',\n",
       "  'property',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'or',\n",
       "  'other',\n",
       "  'of',\n",
       "  'their',\n",
       "  'daughters']]"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "# Remove non-alphanumeric and normalize case\n",
    "words = [[word.lower() for word in line if word.isalnum()] for line in words]\n",
    "words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/piotrm/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['chapter',\n",
       "  'truth',\n",
       "  'universally',\n",
       "  'acknowledged',\n",
       "  'single',\n",
       "  'man',\n",
       "  'possession',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'must',\n",
       "  'want',\n",
       "  'wife'],\n",
       " ['however',\n",
       "  'little',\n",
       "  'known',\n",
       "  'feelings',\n",
       "  'views',\n",
       "  'man',\n",
       "  'may',\n",
       "  'first',\n",
       "  'entering',\n",
       "  'neighbourhood',\n",
       "  'truth',\n",
       "  'well',\n",
       "  'fixed',\n",
       "  'minds',\n",
       "  'surrounding',\n",
       "  'families',\n",
       "  'considered',\n",
       "  'rightful',\n",
       "  'property',\n",
       "  'one',\n",
       "  'daughters']]"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# Filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [[word for word in line if word not in stop_words] for line in words]\n",
    "words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['chapter',\n",
       "  'truth',\n",
       "  'univers',\n",
       "  'acknowledg',\n",
       "  'singl',\n",
       "  'man',\n",
       "  'possess',\n",
       "  'good',\n",
       "  'fortun',\n",
       "  'must',\n",
       "  'want',\n",
       "  'wife'],\n",
       " ['howev',\n",
       "  'littl',\n",
       "  'known',\n",
       "  'feel',\n",
       "  'view',\n",
       "  'man',\n",
       "  'may',\n",
       "  'first',\n",
       "  'enter',\n",
       "  'neighbourhood',\n",
       "  'truth',\n",
       "  'well',\n",
       "  'fix',\n",
       "  'mind',\n",
       "  'surround',\n",
       "  'famili',\n",
       "  'consid',\n",
       "  'right',\n",
       "  'properti',\n",
       "  'one',\n",
       "  'daughter']]"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "# Stem words (fishing, fisher -> fish)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "words = [[porter.stem(word) for word in line] for line in words]\n",
    "words[:2]"
   ]
  },
  {
   "source": [
    "## Create most common words list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_cnt = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_occurences = {}\n",
    "for row in words:\n",
    "    for word in row:\n",
    "        if word_occurences.get(word) is None:\n",
    "            word_occurences[word] = 0\n",
    "        word_occurences[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3951"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "sorted_word_occurences = sorted(word_occurences.items(), key=lambda x: x[1], reverse=True)\n",
    "len(sorted_word_occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words present only once in the entire book\n",
    "sorted_word_occurences = [(word, cnt) for word, cnt in sorted_word_occurences if cnt >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "# get all words, not limit to N most common ones\n",
    "most_common_cnt = len(sorted_word_occurences)\n",
    "most_common_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words_files = {\n",
    "    SHERLOCK: f'words_data/sherlock/most_common_words_{most_common_cnt}.csv',\n",
    "    PRIDE: f'words_data/pride_and_prejudice/most_common_words_{most_common_cnt}.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('mr', 846),\n",
       " ('elizabeth', 622),\n",
       " ('could', 523),\n",
       " ('would', 461),\n",
       " ('darci', 383),\n",
       " ('said', 368),\n",
       " ('bennet', 323),\n",
       " ('much', 319),\n",
       " ('must', 304),\n",
       " ('bingley', 300)]"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "sorted_word_occurences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(most_common_words_files[chosen_book], mode='w') as dict_csv:\n",
    "    csvwriter = csv.writer(dict_csv)\n",
    "    csvwriter.writerows(sorted_word_occurences[:most_common_cnt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "import csv\n",
    "dictionary_arr = []\n",
    "dictionary_dict = {}\n",
    "with open(most_common_words_files[chosen_book], mode='r') as dict_csv:\n",
    "    reader = csv.reader(dict_csv)\n",
    "    for index, row in enumerate(reader):\n",
    "        dictionary_arr.append(row[0])\n",
    "        dictionary_dict[row[0]] = index\n",
    "len(dictionary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6543\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[196, 457, 1210, 370, 740, 49, 675, 28, 213, 8, 117, 288],\n",
       " [56,\n",
       "  29,\n",
       "  224,\n",
       "  38,\n",
       "  402,\n",
       "  49,\n",
       "  27,\n",
       "  51,\n",
       "  214,\n",
       "  412,\n",
       "  457,\n",
       "  22,\n",
       "  458,\n",
       "  198,\n",
       "  44,\n",
       "  164,\n",
       "  313,\n",
       "  1105,\n",
       "  13,\n",
       "  57]]"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "encoded_rows = []\n",
    "for line in words:\n",
    "    encoded_line = []\n",
    "    for word in line:\n",
    "        if word in dictionary_dict:\n",
    "            encoded_line.append(dictionary_dict[word])\n",
    "    encoded_rows.append(encoded_line)\n",
    "print(len(encoded_rows))\n",
    "encoded_rows[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6156"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "minimum_sequence_length = 2\n",
    "encoded_rows = [row for row in encoded_rows if len(row) >= minimum_sequence_length]\n",
    "len(encoded_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save encoded messages to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_words_files = {\n",
    "    SHERLOCK: f'words_data/sherlock/encoded_words_{most_common_cnt}_common.csv',\n",
    "    PRIDE: f'words_data/pride_and_prejudice/encoded_words_{most_common_cnt}_common.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(encoded_words_files[chosen_book], mode='w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(encoded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12, 20, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "row_lengths = {}\n",
    "for index, row in enumerate(encoded_rows):\n",
    "    row_lengths[index] = len(row)\n",
    "row_lengths[0], row_lengths[1], row_lengths[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(2, 2),\n",
       " (4, 2),\n",
       " (5, 2),\n",
       " (6, 2),\n",
       " (10, 2),\n",
       " (14, 2),\n",
       " (18, 2),\n",
       " (21, 2),\n",
       " (22, 2),\n",
       " (24, 2)]"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "sorted_row_lengths = sorted(row_lengths.items(), key=lambda x: x[1])\n",
    "sorted_row_lengths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2078, 53)"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "max_length_row = max(sorted_row_lengths, key=lambda x:x[1])\n",
    "max_length_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[(2, 2),\n",
       "  (4, 2),\n",
       "  (5, 2),\n",
       "  (6, 2),\n",
       "  (10, 2),\n",
       "  (14, 2),\n",
       "  (18, 2),\n",
       "  (21, 2),\n",
       "  (22, 2),\n",
       "  (24, 2),\n",
       "  (27, 2),\n",
       "  (33, 2),\n",
       "  (34, 2),\n",
       "  (40, 2),\n",
       "  (46, 2),\n",
       "  (47, 2),\n",
       "  (48, 2),\n",
       "  (49, 2),\n",
       "  (51, 2),\n",
       "  (59, 2),\n",
       "  (62, 2),\n",
       "  (69, 2),\n",
       "  (70, 2),\n",
       "  (71, 2),\n",
       "  (73, 2),\n",
       "  (77, 2)],\n",
       " [(78, 2),\n",
       "  (82, 2),\n",
       "  (86, 2),\n",
       "  (92, 2),\n",
       "  (94, 2),\n",
       "  (96, 2),\n",
       "  (97, 2),\n",
       "  (101, 2),\n",
       "  (111, 2),\n",
       "  (122, 2),\n",
       "  (133, 2),\n",
       "  (141, 2),\n",
       "  (158, 2),\n",
       "  (168, 2),\n",
       "  (170, 2),\n",
       "  (191, 2),\n",
       "  (192, 2),\n",
       "  (208, 2),\n",
       "  (209, 2),\n",
       "  (213, 2),\n",
       "  (226, 2),\n",
       "  (228, 2),\n",
       "  (233, 2),\n",
       "  (236, 2),\n",
       "  (246, 2),\n",
       "  (247, 2)]]"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "used_rows = set()\n",
    "grouped_rows = []\n",
    "grouping_occured = True\n",
    "while grouping_occured == True:\n",
    "    grouping_occured = False\n",
    "    curr_group = []\n",
    "    grouped_len = 0\n",
    "    for row in sorted_row_lengths:\n",
    "        if row[0] not in used_rows:\n",
    "            curr_len = row[1]\n",
    "            if grouped_len + curr_len <= max_length_row[1]:\n",
    "                curr_group.append(row)\n",
    "                grouped_len += curr_len\n",
    "                used_rows.add(row[0])\n",
    "                grouping_occured = True\n",
    "            else:\n",
    "                break\n",
    "    grouped_rows.append(curr_group)\n",
    "    \n",
    "grouped_rows[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "52\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[50,\n",
       "  0,\n",
       "  6,\n",
       "  62,\n",
       "  80,\n",
       "  0,\n",
       "  69,\n",
       "  167,\n",
       "  225,\n",
       "  90,\n",
       "  70,\n",
       "  740,\n",
       "  50,\n",
       "  0,\n",
       "  427,\n",
       "  215,\n",
       "  902,\n",
       "  78,\n",
       "  21,\n",
       "  252,\n",
       "  50,\n",
       "  582,\n",
       "  132,\n",
       "  99,\n",
       "  164,\n",
       "  57,\n",
       "  260,\n",
       "  173,\n",
       "  787,\n",
       "  350,\n",
       "  1106,\n",
       "  50,\n",
       "  677,\n",
       "  193,\n",
       "  832,\n",
       "  40,\n",
       "  14,\n",
       "  461,\n",
       "  196,\n",
       "  0,\n",
       "  176,\n",
       "  53,\n",
       "  55,\n",
       "  0,\n",
       "  69,\n",
       "  173,\n",
       "  60,\n",
       "  395,\n",
       "  5,\n",
       "  0,\n",
       "  29,\n",
       "  787],\n",
       " [862,\n",
       "  1310,\n",
       "  741,\n",
       "  535,\n",
       "  308,\n",
       "  0,\n",
       "  123,\n",
       "  61,\n",
       "  87,\n",
       "  1426,\n",
       "  71,\n",
       "  581,\n",
       "  24,\n",
       "  327,\n",
       "  1311,\n",
       "  0,\n",
       "  22,\n",
       "  140,\n",
       "  196,\n",
       "  0,\n",
       "  41,\n",
       "  0,\n",
       "  6,\n",
       "  71,\n",
       "  188,\n",
       "  716,\n",
       "  174,\n",
       "  43,\n",
       "  679,\n",
       "  3,\n",
       "  171,\n",
       "  0,\n",
       "  6,\n",
       "  153,\n",
       "  71,\n",
       "  147,\n",
       "  685,\n",
       "  314,\n",
       "  385,\n",
       "  465,\n",
       "  188,\n",
       "  657,\n",
       "  82,\n",
       "  318,\n",
       "  235,\n",
       "  1223,\n",
       "  50,\n",
       "  97,\n",
       "  53,\n",
       "  243,\n",
       "  174,\n",
       "  51]]"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "grouped_rows_data = []\n",
    "for grouped_row in grouped_rows:\n",
    "    curr_row_data = []\n",
    "    for row in grouped_row:\n",
    "        curr_row_data += encoded_rows[row[0]]\n",
    "    grouped_rows_data.append(curr_row_data)\n",
    "print(len(grouped_rows_data[0]))\n",
    "grouped_rows_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_number_files = {\n",
    "    SHERLOCK: f'number_data/sherlock.txt',\n",
    "    PRIDE: f'number_data/pride_and_prejudice.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['50 0 6 62 80 0 69 167 225 90 70 740 50 0 427 215 902 78 21 252 50 582 132 99 164 57 260 173 787 350 1106 50 677 193 832 40 14 461 196 0 176 53 55 0 69 173 60 395 5 0 29 787\\n', '862 1310 741 535 308 0 123 61 87 1426 71 581 24 327 1311 0 22 140 196 0 41 0 6 71 188 716 174 43 679 3 171 0 6 153 71 147 685 314 385 465 188 657 82 318 235 1223 50 97 53 243 174 51\\n', '398 490 152 136 71 86 4 93 434 282 922 0 224 535 632 420 373 0 4 89 398 72 26 144 20 135 4 692 11 9 69 523 31 742 196 0 180 0 321 1227 50 0 39 19 6 1030 117 0 9 571 351 995\\n', '415 550 385 32 29 420 103 1328 902 39 169 0 2 87 351 0 62 1144 31 27 69 21 431 53 614 1470 195 16 442 1471 381 443 8 54 6 370 468 551 263 274 181 281 313 479 71 0 121 409 414 117 114 0\\n', '819 314 364 24 552 546 56 88 385 0 9 0 64 89 251 238 63 280 351 47 127 1476 43 21 1481 0 167 0 1332 7 3 0 88 0 1428 275 103 226 385 1 92 0 714 221 102 46 3 714 948 0 4 34\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(encoded_number_files[chosen_book], mode='w') as outputfile:\n",
    "    lines = []\n",
    "    for row in grouped_rows_data:\n",
    "        curr_line = \" \".join([str(item) for item in row])+'\\n'\n",
    "        lines.append(curr_line)\n",
    "    outputfile.writelines(lines)\n",
    "    print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd09f19d2723d3518f25eda5a4b6595adeb2af7874d49ee5fd9c328181e4bd69f4c",
   "display_name": "Python 3.7.3 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "9f19d2723d3518f25eda5a4b6595adeb2af7874d49ee5fd9c328181e4bd69f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}