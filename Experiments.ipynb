{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_cnt = 2000\n",
    "SHERLOCK = 'sher'\n",
    "METAMORPHOSIS = 'meta'\n",
    "PRIDE = 'prid'\n",
    "chosen_book = PRIDE\n",
    "encoded_words_files = {\n",
    "    SHERLOCK: f'experiments/words_data/sherlock/encoded_words_{most_common_cnt}_common.csv',\n",
    "    PRIDE: f'experiments/words_data/pride_and_prejudice/encoded_words_{most_common_cnt}_common.csv'\n",
    "}"
   ]
  },
  {
   "source": [
    "## Read data from CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[[196],\n",
       "  [457],\n",
       "  [1210],\n",
       "  [370],\n",
       "  [740],\n",
       "  [49],\n",
       "  [675],\n",
       "  [28],\n",
       "  [213],\n",
       "  [8],\n",
       "  [117],\n",
       "  [288]],\n",
       " [[56],\n",
       "  [29],\n",
       "  [224],\n",
       "  [38],\n",
       "  [402],\n",
       "  [49],\n",
       "  [27],\n",
       "  [51],\n",
       "  [214],\n",
       "  [412],\n",
       "  [457],\n",
       "  [22],\n",
       "  [458],\n",
       "  [198],\n",
       "  [1782],\n",
       "  [44],\n",
       "  [164],\n",
       "  [313],\n",
       "  [1105],\n",
       "  [13],\n",
       "  [57]]]"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "import csv\n",
    "tns_data = []\n",
    "with open(encoded_words_files[chosen_book], mode='r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        tns_data.append([ [int(item)] for item in row ])\n",
    "tns_data[:2]\n"
   ]
  },
  {
   "source": [
    "## Run TNS algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TNS import TNS, Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "125,170 ==> 165  sup= 5  conf= 0.5\n158,196 ==> 128  sup= 5  conf= 0.7142857142857143\n1,338 ==> 347  sup= 5  conf= 0.7142857142857143\n1,5,11 ==> 6  sup= 5  conf= 0.5\n11,15,338 ==> 347  sup= 5  conf= 0.8333333333333334\n900 ==> 10  sup= 6  conf= 0.5454545454545454\n1193 ==> 30  sup= 6  conf= 0.8571428571428571\n1101 ==> 647  sup= 6  conf= 1.0\n13,226 ==> 24  sup= 6  conf= 0.6666666666666666\n11,385 ==> 9  sup= 6  conf= 0.75\n33,338 ==> 347  sup= 6  conf= 1.0\n385 ==> 11  sup= 8  conf= 0.5\n371 ==> 513  sup= 15  conf= 0.6818181818181818\n66,338 ==> 347  sup= 15  conf= 0.8823529411764706\n11,338 ==> 347  sup= 16  conf= 0.9411764705882353\n15,338 ==> 347  sup= 17  conf= 0.9444444444444444\n226 ==> 24  sup= 19  conf= 0.5588235294117647\n196 ==> 1  sup= 24  conf= 0.6666666666666666\n135 ==> 277  sup= 31  conf= 0.7380952380952381\n338 ==> 347  sup= 31  conf= 0.96875\n\n"
     ]
    }
   ],
   "source": [
    "data = Data(tns_data)\n",
    "algorithm = TNS()\n",
    "rules = algorithm.run(data, k=20, min_conf=0.5, delta=2)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<Rule.Rule at 0x105cbbbb0>,\n",
       " <Rule.Rule at 0x1089c46a0>,\n",
       " <Rule.Rule at 0x107d06190>,\n",
       " <Rule.Rule at 0x1089ebf10>,\n",
       " <Rule.Rule at 0x108ca9df0>,\n",
       " <Rule.Rule at 0x105b31040>,\n",
       " <Rule.Rule at 0x10681e1f0>,\n",
       " <Rule.Rule at 0x1089a5e80>,\n",
       " <Rule.Rule at 0x105b6a520>,\n",
       " <Rule.Rule at 0x1089d5e20>,\n",
       " <Rule.Rule at 0x108b829a0>,\n",
       " <Rule.Rule at 0x105fba8b0>,\n",
       " <Rule.Rule at 0x10899c0a0>,\n",
       " <Rule.Rule at 0x108d38940>,\n",
       " <Rule.Rule at 0x1061f13a0>,\n",
       " <Rule.Rule at 0x108d04c10>,\n",
       " <Rule.Rule at 0x108681520>,\n",
       " <Rule.Rule at 0x108362f40>,\n",
       " <Rule.Rule at 0x1086dc3a0>,\n",
       " <Rule.Rule at 0x108998490>]"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "rules_list = []\n",
    "while True:\n",
    "    item = rules.pop_minimum()\n",
    "    if item:\n",
    "        rules_list.append(item)\n",
    "    else:\n",
    "        break\n",
    "rules_list    "
   ]
  },
  {
   "source": [
    "## Read most common words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words_files = {\n",
    "    SHERLOCK: f'experiments/words_data/sherlock/most_common_words_{most_common_cnt}.csv',\n",
    "    PRIDE: f'experiments/words_data/pride_and_prejudice/most_common_words_{most_common_cnt}.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dictionary_arr = []\n",
    "# dictionary_dict = {}\n",
    "with open(most_common_words_files[chosen_book], mode='r') as dict_csv:\n",
    "    reader = csv.reader(dict_csv)\n",
    "    for index, row in enumerate(reader):\n",
    "        dictionary_arr.append(row[0])\n",
    "        # dictionary_dict[row[0]] = index\n"
   ]
  },
  {
   "source": [
    "## Map rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_list_mapped = []\n",
    "for rule in rules_list:\n",
    "    ante = [ dictionary_arr[ind] for ind in rule.antecedents ]\n",
    "    cons = [ dictionary_arr[ind] for ind in rule.consequents ]\n",
    "    rules_list_mapped.append((ante, cons, rule.support, rule.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "turn, eye ==> toward  sup= 5  conf= 0.5\nnext, chapter ==> morn  sup= 5  conf= 0.7142857142857143\nelizabeth, de ==> bourgh  sup= 5  conf= 0.7142857142857143\nelizabeth, said, miss ==> bennet  sup= 5  conf= 0.5\nmiss, ladi, de ==> bourgh  sup= 5  conf= 0.8333333333333334\nelder ==> sister  sup= 6  conf= 0.5454545454545454\ngeorg ==> wickham  sup= 6  conf= 0.8571428571428571\ngracechurch ==> street  sup= 6  conf= 1.0\none, dare ==> say  sup= 6  conf= 0.6666666666666666\nmiss, hurst ==> bingley  sup= 6  conf= 0.75\ncollin, de ==> bourgh  sup= 6  conf= 1.0\nhurst ==> miss  sup= 8  conf= 0.5\nthousand ==> pound  sup= 15  conf= 0.6818181818181818\ncatherin, de ==> bourgh  sup= 15  conf= 0.8823529411764706\nmiss, de ==> bourgh  sup= 16  conf= 0.9411764705882353\nladi, de ==> bourgh  sup= 17  conf= 0.9444444444444444\ndare ==> say  sup= 19  conf= 0.5588235294117647\nchapter ==> elizabeth  sup= 24  conf= 0.6666666666666666\nsir ==> william  sup= 31  conf= 0.7380952380952381\nde ==> bourgh  sup= 31  conf= 0.96875\n"
     ]
    }
   ],
   "source": [
    "for rule in rules_list_mapped:\n",
    "    print(f\"{', '.join(rule[0])} ==> {', '.join(rule[1])}  sup= {rule[2]}  conf= {rule[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_files = {\n",
    "    SHERLOCK: f'experiments/words_data/sherlock/rules_{most_common_cnt}_common_words.csv',\n",
    "    PRIDE: f'experiments/words_data/pride_and_prejudice/rules_{most_common_cnt}_common_words.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(rules_files[chosen_book], mode='w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(rules_list_mapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}